import os
import pandas as pd
import joblib
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import pmdarima as pm  # Auto ARIMA
from statsmodels.tsa.stattools import adfuller  # ADF test for stationarity

# Disable GPU (Not needed)
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
GENERATED_DIR = os.path.join(BASE_DIR, "generated_files")
if not os.path.exists(GENERATED_DIR):
    os.makedirs(GENERATED_DIR)

def add_time_lags(df, target_col, lags=7):
    """Creates lagged features for time-series forecasting."""
    for lag in range(1, lags + 1):
        df[f"{target_col}_lag{lag}"] = df[target_col].shift(lag)
    df.dropna(inplace=True)  # Remove rows with NaN values
    return df

def check_stationarity(series):
    """Perform Augmented Dickey-Fuller (ADF) test for stationarity."""
    result = adfuller(series.dropna())  # Drop NaN values
    p_value = result[1]
    
    if p_value > 0.05:
        print(f"‚ö†Ô∏è Warning: Data is NOT stationary (p={p_value:.4f}). Differencing is needed.")
    else:
        print(f"‚úÖ Data is stationary (p={p_value:.4f}). No differencing required.")

    return p_value <= 0.05  # Return True if stationary

def optimize_arima(y):
    """Automatically selects the best (p,d,q) values for ARIMA."""
    print("üîç Optimizing ARIMA order...")
    
    auto_arima_model = pm.auto_arima(
        y, seasonal=False, stepwise=True, suppress_warnings=True, trace=True
    )
    
    return auto_arima_model.order  # Returns (p,d,q)

def train_predictive_model(primary_csv, related_csv, model_type="linear_regression"):
    """Trains a predictive model using supervised learning with time-lagged features and cross-validation."""
    try:
        print("üì• Loading datasets...")
        primary_df = pd.read_csv(primary_csv)
        related_df = pd.read_csv(related_csv)
    except Exception as e:
        return None, None, f"‚ùå Error reading CSV files: {e}"

    print("üîÑ Merging datasets...")
    merged_df = pd.merge(primary_df, related_df, on='date', how='outer').fillna(0)

    if merged_df.empty:
        return None, None, "‚ùå Merged dataset is empty."

    print("üöÄ Preparing training data...")
    target = primary_df.columns[1]  # First feature column as target variable
    features = [col for col in related_df.columns if col != "date"]

    # ‚úÖ Apply time-lagging
    merged_df = add_time_lags(merged_df, target, lags=7)

    # ‚úÖ Ensure `date` column is formatted correctly for time-series models
    if 'date' in merged_df.columns:
        merged_df['date'] = pd.to_datetime(merged_df['date'], errors='coerce', utc=True)
        merged_df.set_index('date', inplace=True)  # Set as index

    X = merged_df[features]
    y = merged_df[target]

    # ‚úÖ Ensure `y` is a 1D Series for ARIMA
    if isinstance(y, pd.DataFrame):
        y = y.iloc[:, 0]  

    print(f"üìä Selected features: {features}")

    # ‚úÖ Standardize features for better model performance
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    print(f"üèãÔ∏è Training model: {model_type}...")

    # ‚úÖ Model Selection
    model = None
    y_pred = None
    y_true = y  # Default for non-ARIMA models

    if model_type == "linear_regression":
        model = LinearRegression()
    
    elif model_type == "random_forest":
        model = RandomForestRegressor(n_estimators=100, max_depth=15, min_samples_split=2, random_state=42)

    elif model_type == "arima":
        from statsmodels.tsa.arima.model import ARIMA

        # ‚úÖ Ensure `y` has a proper datetime index
        if not isinstance(y.index, pd.DatetimeIndex):
            print("‚ö†Ô∏è ARIMA requires a datetime index. Assigning a default range...")
            y.index = pd.date_range(start="2020-01-01", periods=len(y), freq="D")

        # ‚úÖ Check if ARIMA is suitable
        y_shifted = y.shift(1).dropna()  # Remove NaN values before checking correlation
        y_shifted_next = y_shifted.shift(1).dropna()  # Ensure both series have same length

        if len(y_shifted) > 1 and len(y_shifted_next) == len(y_shifted) and r2_score(y_shifted, y_shifted_next) < 0.5:
            print("‚ö†Ô∏è ARIMA is not a good fit for this dataset. Consider a different model.")
            return None, None, "‚ö†Ô∏è ARIMA is not suitable for this dataset. Try another model."

        try:
            model = ARIMA(y, order=(5,1,0)).fit()
            y_pred = model.predict(start=len(y), end=len(y)+4)
            y_true = y.iloc[-len(y_pred):]  # Align y_true for evaluation
        except Exception as e:
            print(f"‚ùå ARIMA Model Training Failed: {e}")
            return None, None, f"‚ùå ARIMA Model Failed: {e}"


    # ‚úÖ Train non-ARIMA models
    if model_type in ["linear_regression", "random_forest"]:
        try:
            model.fit(X_scaled, y)
            y_pred = model.predict(X_scaled)
        except Exception as e:
            print(f"‚ùå Model Training Failed: {e}")
            return None, None, f"‚ùå Model Training Failed: {e}"

    # ‚úÖ Compute Model Performance Metrics
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)

    print(f"‚úÖ Model trained successfully. üîπ MSE: {mse:.4f} üîπ RMSE: {rmse:.4f} üîπ R¬≤ Score: {r2:.4f}")

    # ‚úÖ Save Model
    model_filename = os.path.join(GENERATED_DIR, "predictive_model.pkl")
    joblib.dump(model, model_filename)
    print(f"üíæ Model saved to: {model_filename}")

    # ‚úÖ Generate `run_analysis.py` script
    script_filename = os.path.join(GENERATED_DIR, "run_analysis.py")
    try:
        with open(script_filename, "w") as f:
            f.write(f"""
import joblib
import pandas as pd
from sklearn.metrics import mean_squared_error, r2_score

# Load trained model
model = joblib.load("predictive_model.pkl")

df = pd.read_csv("{primary_csv}")
X = df.iloc[:, 1:]
y = df.iloc[:, 0]

y_pred = model.predict(X)

mse = mean_squared_error(y, y_pred)
r2 = r2_score(y, y_pred)

print("üîé Model Performance:")
print(f"Mean Squared Error: {{mse:.4f}}")
print(f"R¬≤ Score: {{r2:.4f}}")
""")
        print(f"üíæ Script saved to: {script_filename}")
    except Exception as e:
        print(f"‚ùå Error saving script: {e}")

    return model_filename, script_filename, f"‚úÖ Model trained successfully. üîπ MSE: {mse:.4f} üîπ RMSE: {rmse:.4f} üîπ R¬≤ Score: {r2:.4f}"
